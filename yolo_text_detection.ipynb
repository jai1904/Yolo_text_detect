{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 10.750582\n",
      "boxes[2] = [ 8.426533   3.2713668 -0.5313436 -4.9413733]\n",
      "classes[2] = 7\n",
      "scores.shape = (None,)\n",
      "boxes.shape = (None, 4)\n",
      "classes.shape = (None,)\n",
      "iou for intersecting boxes = 0.14285714285714285\n",
      "iou for non-intersecting boxes = 1.0\n",
      "iou for boxes that only touch at vertices = 0.0\n",
      "iou for boxes that only touch at edges = 0.0\n",
      "WARNING:tensorflow:From c:\\users\\jaijui\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "scores[2] = 6.938395\n",
      "boxes[2] = [-5.299932    3.1379814   4.450367    0.95942086]\n",
      "classes[2] = -2.2452729\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n",
      "scores[2] = 138.79124\n",
      "boxes[2] = [1292.3297  -278.52167 3876.9893  -835.56494]\n",
      "classes[2] = 54\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\two_class.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6faa1e499a77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\two_class.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\yolo_anchors.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m720.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1280.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-6faa1e499a77>\u001b[0m in \u001b[0;36mread_classes\u001b[1;34m(classes_path)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\two_class.txt'"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "def compose(*funcs):\n",
    "    \n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "##################################Jai you just collected all here to remember don't use all.\n",
    "\n",
    "\"\"\"Darknet19 Model Defined in Keras.\"\"\"\n",
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "_DarknetConv2D = partial(Conv2D, padding='same')\n",
    "\n",
    "\n",
    "@functools.wraps(Conv2D)\n",
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet weight regularizer for Convolution2D.\"\"\"\n",
    "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return _DarknetConv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "def bottleneck_block(outer_filters, bottleneck_filters):\n",
    "    \"\"\"Bottleneck block of 3x3, 1x1, 3x3 convolutions.\"\"\"\n",
    "    return compose(\n",
    "        DarknetConv2D_BN_Leaky(outer_filters, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(bottleneck_filters, (1, 1)),\n",
    "        DarknetConv2D_BN_Leaky(outer_filters, (3, 3)))\n",
    "\n",
    "\n",
    "def bottleneck_x2_block(outer_filters, bottleneck_filters):\n",
    "    \"\"\"Bottleneck block of 3x3, 1x1, 3x3, 1x1, 3x3 convolutions.\"\"\"\n",
    "    return compose(\n",
    "        bottleneck_block(outer_filters, bottleneck_filters),\n",
    "        DarknetConv2D_BN_Leaky(bottleneck_filters, (1, 1)),\n",
    "        DarknetConv2D_BN_Leaky(outer_filters, (3, 3)))\n",
    "\n",
    "\n",
    "def darknet_body():\n",
    "    \"\"\"Generate first 18 conv layers of Darknet-19.\"\"\"\n",
    "    return compose(\n",
    "        DarknetConv2D_BN_Leaky(32, (3, 3)),\n",
    "        MaxPooling2D(),\n",
    "        DarknetConv2D_BN_Leaky(64, (3, 3)),\n",
    "        MaxPooling2D(),\n",
    "        bottleneck_block(128, 64),\n",
    "        MaxPooling2D(),\n",
    "        bottleneck_block(256, 128),\n",
    "        MaxPooling2D(),\n",
    "        bottleneck_x2_block(512, 256),\n",
    "        MaxPooling2D(),\n",
    "        bottleneck_x2_block(1024, 512))\n",
    "\n",
    "\n",
    "def darknet19(inputs):\n",
    "    \"\"\"Generate Darknet-19 model for Imagenet classification.\"\"\"\n",
    "    body = darknet_body()(inputs)\n",
    "    logits = DarknetConv2D(1000, (1, 1), activation='softmax')(body)\n",
    "    return Model(inputs, logits)\n",
    "################################\n",
    "\n",
    "\"\"\"YOLO_v2 Model Defined in Keras.\"\"\"\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "voc_anchors = np.array(\n",
    "    [[1.08, 1.19], [3.42, 4.41], [6.63, 11.38], [9.42, 5.11], [16.62, 10.52]])\n",
    "\n",
    "voc_classes = [\"dec_text\",\"dec_blank\"]\n",
    "\n",
    "def space_to_depth_x2(x):\n",
    "    \"\"\"Thin wrapper for Tensorflow space_to_depth with block_size=2.\"\"\"\n",
    "    import tensorflow as tf\n",
    "    return tf.space_to_depth(x, block_size=2)\n",
    "\n",
    "\n",
    "def space_to_depth_x2_output_shape(input_shape):\n",
    "    \"\"\"Determine space_to_depth output shape for block_size=2.\n",
    "\n",
    "    Note: For Lambda with TensorFlow backend, output shape may not be needed.\n",
    "    \"\"\"\n",
    "    return (input_shape[0], input_shape[1] // 2, input_shape[2] // 2, 4 *input_shape[3]) if input_shape[1] else (input_shape[0], None, None,4 * input_shape[3])\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V2 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body()(inputs))\n",
    "    conv20 = compose(\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)))(darknet.output)\n",
    "\n",
    "    conv13 = darknet.layers[43].output\n",
    "    conv21 = DarknetConv2D_BN_Leaky(64, (1, 1))(conv13)\n",
    "    conv21_reshaped = Lambda(\n",
    "        space_to_depth_x2,\n",
    "        output_shape=space_to_depth_x2_output_shape,\n",
    "        name='space_to_depth')(conv21)\n",
    "\n",
    "    x = concatenate([conv21_reshaped, conv20])\n",
    "    x = DarknetConv2D_BN_Leaky(1024, (3, 3))(x)\n",
    "    x = DarknetConv2D(num_anchors * (num_classes + 5), (1, 1))(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes):\n",
    "    \n",
    "    num_anchors = len(anchors)\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
    "   \n",
    "    conv_dims = K.shape(feats)[1:3] \n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "    \n",
    "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_confidence, box_xy, box_wh, box_class_probs\n",
    "\n",
    "\n",
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  \n",
    "        box_mins[..., 0:1],  \n",
    "        box_maxes[..., 1:2],  \n",
    "        box_maxes[..., 0:1]  \n",
    "    ])\n",
    "\n",
    "\n",
    "def yolo_loss(args,anchors,num_classes,rescore_confidence=False,print_loss=False):\n",
    "   \n",
    "    \n",
    "    (yolo_output, true_boxes, detectors_mask, matching_true_boxes) = args\n",
    "    num_anchors = len(anchors)\n",
    "    object_scale = 5\n",
    "    no_object_scale = 1\n",
    "    class_scale = 1\n",
    "    coordinates_scale = 1\n",
    "    pred_xy, pred_wh, pred_confidence, pred_class_prob = yolo_head(yolo_output, anchors, num_classes)\n",
    "    yolo_output_shape = K.shape(yolo_output)\n",
    "    feats = K.reshape(yolo_output, [\n",
    "        -1, yolo_output_shape[1], yolo_output_shape[2], num_anchors,\n",
    "        num_classes + 5\n",
    "    ])\n",
    "    pred_boxes = K.concatenate(\n",
    "        (K.sigmoid(feats[..., 0:2]), feats[..., 2:4]), axis=-1)\n",
    "\n",
    "    pred_xy = K.expand_dims(pred_xy, 4)\n",
    "    pred_wh = K.expand_dims(pred_wh, 4)\n",
    "\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins = pred_xy - pred_wh_half\n",
    "    pred_maxes = pred_xy + pred_wh_half\n",
    "\n",
    "    true_boxes_shape = K.shape(true_boxes)\n",
    "\n",
    "    true_boxes = K.reshape(true_boxes, [\n",
    "        true_boxes_shape[0], 1, 1, 1, true_boxes_shape[1], true_boxes_shape[2]\n",
    "    ])\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins = true_xy - true_wh_half\n",
    "    true_maxes = true_xy + true_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores = intersect_areas / union_areas\n",
    "\n",
    "    best_ious = K.max(iou_scores, axis=4)  # Best IOU scores.\n",
    "    best_ious = K.expand_dims(best_ious)\n",
    "    object_detections = K.cast(best_ious > 0.6, K.dtype(best_ious))\n",
    "\n",
    "    no_object_weights = (no_object_scale * (1 - object_detections) *\n",
    "                         (1 - detectors_mask))\n",
    "    no_objects_loss = no_object_weights * K.square(-pred_confidence)\n",
    "\n",
    "    if rescore_confidence:\n",
    "        objects_loss = (object_scale * detectors_mask *\n",
    "                        K.square(best_ious - pred_confidence))\n",
    "    else:\n",
    "        objects_loss = (object_scale * detectors_mask *\n",
    "                        K.square(1 - pred_confidence))\n",
    "    confidence_loss = objects_loss + no_objects_loss\n",
    "\n",
    "    matching_classes = K.cast(matching_true_boxes[..., 4], 'int32')\n",
    "    matching_classes = K.one_hot(matching_classes, num_classes)\n",
    "    classification_loss = (class_scale * detectors_mask *\n",
    "                           K.square(matching_classes - pred_class_prob))\n",
    "\n",
    "    matching_boxes = matching_true_boxes[..., 0:4]\n",
    "    coordinates_loss = (coordinates_scale * detectors_mask *\n",
    "                        K.square(matching_boxes - pred_boxes))\n",
    "\n",
    "    confidence_loss_sum = K.sum(confidence_loss)\n",
    "    classification_loss_sum = K.sum(classification_loss)\n",
    "    coordinates_loss_sum = K.sum(coordinates_loss)\n",
    "    total_loss = 0.5 * (\n",
    "        confidence_loss_sum + classification_loss_sum + coordinates_loss_sum)\n",
    "    if print_loss:\n",
    "        total_loss = tf.Print(\n",
    "            total_loss, [\n",
    "                total_loss, confidence_loss_sum, classification_loss_sum,\n",
    "                coordinates_loss_sum\n",
    "            ],\n",
    "            message='yolo_loss, conf_loss, class_loss, box_coord_loss:')\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def yolo(inputs, anchors, num_classes):\n",
    "    \"\"\"Generate a complete YOLO_v2 localization model.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    body = yolo_body(inputs, num_anchors, num_classes)\n",
    "    outputs = yolo_head(body.output, anchors, num_classes)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=.6):\n",
    "    \"\"\"Filter YOLO boxes based on object and class confidence.\"\"\"\n",
    "\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_classes = K.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = K.max(box_scores, axis=-1)\n",
    "    prediction_mask = box_class_scores >= threshold\n",
    "\n",
    "    # TODO: Expose tf.boolean_mask to Keras backend?\n",
    "    boxes = tf.boolean_mask(boxes, prediction_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "    classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def yolo_eval(yolo_outputs,\n",
    "              image_shape,\n",
    "              max_boxes=10,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input batch and return filtered boxes.\"\"\"\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    boxes, scores, classes = yolo_filter_boxes(\n",
    "        box_confidence, boxes, box_class_probs, threshold=score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "\n",
    "    # TODO: Something must be done about this ugly hack!\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "    nms_index = tf.image.non_max_suppression(\n",
    "        boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, nms_index)\n",
    "    scores = K.gather(scores, nms_index)\n",
    "    classes = K.gather(classes, nms_index)\n",
    "    \n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, anchors, image_size):\n",
    "    \n",
    "    height, width = image_size\n",
    "    num_anchors = len(anchors)\n",
    "    # Downsampling factor of 5x 2-stride max_pools == 32.\n",
    "    # TODO: Remove hardcoding of downscaling calculations.\n",
    "    assert height % 32 == 0, 'Image sizes in YOLO_v2 must be multiples of 32.'\n",
    "    assert width % 32 == 0, 'Image sizes in YOLO_v2 must be multiples of 32.'\n",
    "    conv_height = height // 32\n",
    "    conv_width = width // 32\n",
    "    num_box_params = true_boxes.shape[1]\n",
    "    detectors_mask = np.zeros(\n",
    "        (conv_height, conv_width, num_anchors, 1), dtype=np.float32)\n",
    "    matching_true_boxes = np.zeros(\n",
    "        (conv_height, conv_width, num_anchors, num_box_params),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    for box in true_boxes:\n",
    "        # scale box to convolutional feature spatial dimensions\n",
    "        box_class = box[4:5]\n",
    "        box = box[0:4] * np.array(\n",
    "            [conv_width, conv_height, conv_width, conv_height])\n",
    "        i = np.floor(box[1]).astype('int')\n",
    "        j = min(np.floor(box[0]).astype('int'),1)\n",
    "        best_iou = 0\n",
    "        best_anchor = 0\n",
    "                \n",
    "        for k, anchor in enumerate(anchors):\n",
    "            # Find IOU between box shifted to origin and anchor box.\n",
    "            box_maxes = box[2:4] / 2.\n",
    "            box_mins = -box_maxes\n",
    "            anchor_maxes = (anchor / 2.)\n",
    "            anchor_mins = -anchor_maxes\n",
    "\n",
    "            intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "            intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "            intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "            intersect_area = intersect_wh[0] * intersect_wh[1]\n",
    "            box_area = box[2] * box[3]\n",
    "            anchor_area = anchor[0] * anchor[1]\n",
    "            iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_anchor = k\n",
    "                \n",
    "        if best_iou > 0:\n",
    "            detectors_mask[i, j, best_anchor] = 1\n",
    "            adjusted_box = np.array(\n",
    "                [\n",
    "                    box[0] - j, box[1] - i,\n",
    "                    np.log(box[2] / anchors[best_anchor][0]),\n",
    "                    np.log(box[3] / anchors[best_anchor][1]), box_class\n",
    "                ],\n",
    "                dtype=np.float32)\n",
    "            matching_true_boxes[i, j, best_anchor] = adjusted_box\n",
    "    return detectors_mask, matching_true_boxes\n",
    "\n",
    "\n",
    "###UTILS\n",
    "import colorsys\n",
    "import imghdr\n",
    "import os\n",
    "import random\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def read_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def read_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "    return anchors\n",
    "\n",
    "def generate_colors(class_names):\n",
    "    hsv_tuples = [(x / len(class_names), 1., 1.) for x in range(len(class_names))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "    return colors\n",
    "\n",
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "    return boxes\n",
    "\n",
    "def preprocess_image(img_path, model_image_size):\n",
    "    image_type = imghdr.what(img_path)\n",
    "    image = Image.open(img_path)\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    return image, image_data\n",
    "\n",
    "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
    "    \n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "       \n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "voc_anchors = np.array(\n",
    "    [[1.08, 1.19], [3.42, 4.41], [6.63, 11.38], [9.42, 5.11], [16.62, 10.52]])\n",
    "\n",
    "voc_classes = [\n",
    "    \"text_dec\",\"bla\"\n",
    "]\n",
    "\n",
    "\n",
    "def space_to_depth_x2(x):\n",
    "    \"\"\"Thin wrapper for Tensorflow space_to_depth with block_size=2.\"\"\"\n",
    "    # Import currently required to make Lambda work.\n",
    "    # See: https://github.com/fchollet/keras/issues/5088#issuecomment-273851273\n",
    "    import tensorflow as tf\n",
    "    return tf.space_to_depth(x, block_size=2)\n",
    "\n",
    "\n",
    "def space_to_depth_x2_output_shape(input_shape):\n",
    "    \"\"\"Determine space_to_depth output shape for block_size=2.\n",
    "\n",
    "    Note: For Lambda with TensorFlow backend, output shape may not be needed.\n",
    "    \"\"\"\n",
    "    return (input_shape[0], input_shape[1] // 2, input_shape[2] // 2, 4 *\n",
    "            input_shape[3]) if input_shape[1] else (input_shape[0], None, None,\n",
    "                                                    4 * input_shape[3])\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V2 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body()(inputs))\n",
    "    conv20 = compose(\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)))(darknet.output)\n",
    "\n",
    "    conv13 = darknet.layers[43].output\n",
    "    conv21 = DarknetConv2D_BN_Leaky(64, (1, 1))(conv13)\n",
    "    conv21_reshaped = Lambda(\n",
    "        space_to_depth_x2,\n",
    "        output_shape=space_to_depth_x2_output_shape,\n",
    "        name='space_to_depth')(conv21)\n",
    "\n",
    "    x = concatenate([conv21_reshaped, conv20])\n",
    "    x = DarknetConv2D_BN_Leaky(1024, (3, 3))(x)\n",
    "    x = DarknetConv2D(num_anchors * (num_classes + 5), (1, 1))(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes):\n",
    "\n",
    "    num_anchors = len(anchors)\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
    "    conv_dims = K.shape(feats)[1:3]  \n",
    "\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "    \n",
    "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_confidence, box_xy, box_wh, box_class_probs\n",
    "\n",
    "\n",
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  \n",
    "        box_mins[..., 0:1],  \n",
    "        box_maxes[..., 1:2],  \n",
    "        box_maxes[..., 0:1]  \n",
    "    ])\n",
    "\n",
    "\n",
    "def yolo_loss(args,\n",
    "              anchors,\n",
    "              num_classes,\n",
    "              rescore_confidence=False,\n",
    "              print_loss=False):\n",
    "    \n",
    "    (yolo_output, true_boxes, detectors_mask, matching_true_boxes) = args\n",
    "    num_anchors = len(anchors)\n",
    "    object_scale = 5\n",
    "    no_object_scale = 1\n",
    "    class_scale = 1\n",
    "    coordinates_scale = 1\n",
    "    pred_xy, pred_wh, pred_confidence, pred_class_prob = yolo_head(\n",
    "        yolo_output, anchors, num_classes)\n",
    "\n",
    "    \n",
    "    # TODO: Remove extra computation shared with yolo_head.\n",
    "    yolo_output_shape = K.shape(yolo_output)\n",
    "    feats = K.reshape(yolo_output, [\n",
    "        -1, yolo_output_shape[1], yolo_output_shape[2], num_anchors,\n",
    "        num_classes + 5\n",
    "    ])\n",
    "    pred_boxes = K.concatenate(\n",
    "        (K.sigmoid(feats[..., 0:2]), feats[..., 2:4]), axis=-1)\n",
    "\n",
    "\n",
    "    pred_xy = K.expand_dims(pred_xy, 4)\n",
    "    pred_wh = K.expand_dims(pred_wh, 4)\n",
    "\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins = pred_xy - pred_wh_half\n",
    "    pred_maxes = pred_xy + pred_wh_half\n",
    "\n",
    "    true_boxes_shape = K.shape(true_boxes)\n",
    "\n",
    "    # batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params\n",
    "    true_boxes = K.reshape(true_boxes, [\n",
    "        true_boxes_shape[0], 1, 1, 1, true_boxes_shape[1], true_boxes_shape[2]\n",
    "    ])\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "\n",
    "    # Find IOU of each predicted box with each ground truth box.\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins = true_xy - true_wh_half\n",
    "    true_maxes = true_xy + true_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores = intersect_areas / union_areas\n",
    "\n",
    "\n",
    "    best_ious = K.max(iou_scores, axis=4)  # Best IOU scores.\n",
    "    best_ious = K.expand_dims(best_ious)\n",
    "\n",
    "    # A detector has found an object if IOU > thresh for some true box.\n",
    "    object_detections = K.cast(best_ious > 0.6, K.dtype(best_ious))\n",
    "\n",
    "\n",
    "    no_object_weights = (no_object_scale * (1 - object_detections) *\n",
    "                         (1 - detectors_mask))\n",
    "    no_objects_loss = no_object_weights * K.square(-pred_confidence)\n",
    "\n",
    "    if rescore_confidence:\n",
    "        objects_loss = (object_scale * detectors_mask *\n",
    "                        K.square(best_ious - pred_confidence))\n",
    "    else:\n",
    "        objects_loss = (object_scale * detectors_mask *\n",
    "                        K.square(1 - pred_confidence))\n",
    "    confidence_loss = objects_loss + no_objects_loss\n",
    "\n",
    "    # Classification loss for matching detections.\n",
    "    # NOTE: YOLO does not use categorical cross-entropy loss here.\n",
    "    matching_classes = K.cast(matching_true_boxes[..., 4], 'int32')\n",
    "    matching_classes = K.one_hot(matching_classes, num_classes)\n",
    "    classification_loss = (class_scale * detectors_mask *\n",
    "                           K.square(matching_classes - pred_class_prob))\n",
    "\n",
    "    # Coordinate loss for matching detection boxes.\n",
    "    matching_boxes = matching_true_boxes[..., 0:4]\n",
    "    coordinates_loss = (coordinates_scale * detectors_mask *\n",
    "                        K.square(matching_boxes - pred_boxes))\n",
    "\n",
    "    confidence_loss_sum = K.sum(confidence_loss)\n",
    "    classification_loss_sum = K.sum(classification_loss)\n",
    "    coordinates_loss_sum = K.sum(coordinates_loss)\n",
    "    total_loss = 0.5 * (\n",
    "        confidence_loss_sum + classification_loss_sum + coordinates_loss_sum)\n",
    "    if print_loss:\n",
    "        total_loss = tf.Print(\n",
    "            total_loss, [\n",
    "                total_loss, confidence_loss_sum, classification_loss_sum,\n",
    "                coordinates_loss_sum\n",
    "            ],\n",
    "            message='yolo_loss, conf_loss, class_loss, box_coord_loss:')\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def yolo(inputs, anchors, num_classes):\n",
    " \n",
    "    num_anchors = len(anchors)\n",
    "    body = yolo_body(inputs, num_anchors, num_classes)\n",
    "    outputs = yolo_head(body.output, anchors, num_classes)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=.6):\n",
    "   \n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_classes = K.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = K.max(box_scores, axis=-1)\n",
    "    prediction_mask = box_class_scores >= threshold\n",
    "\n",
    "    boxes = tf.boolean_mask(boxes, prediction_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "    classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def yolo_eval(yolo_outputs,\n",
    "              image_shape,\n",
    "              max_boxes=10,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input batch and return filtered boxes.\"\"\"\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    boxes, scores, classes = yolo_filter_boxes(\n",
    "        box_confidence, boxes, box_class_probs, threshold=score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "\n",
    "    # TODO: Something must be done about this ugly hack!\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "    nms_index = tf.image.non_max_suppression(\n",
    "        boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, nms_index)\n",
    "    scores = K.gather(scores, nms_index)\n",
    "    classes = K.gather(classes, nms_index)\n",
    "    \n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, anchors, image_size):\n",
    "   \n",
    "    height, width = image_size\n",
    "    num_anchors = len(anchors)\n",
    "    \n",
    "    \n",
    "    assert height % 32 == 0, 'Image sizes in YOLO_v2 must be multiples of 32.'\n",
    "    assert width % 32 == 0, 'Image sizes in YOLO_v2 must be multiples of 32.'\n",
    "    conv_height = height // 32\n",
    "    conv_width = width // 32\n",
    "    num_box_params = true_boxes.shape[1]\n",
    "    detectors_mask = np.zeros(\n",
    "        (conv_height, conv_width, num_anchors, 1), dtype=np.float32)\n",
    "    matching_true_boxes = np.zeros(\n",
    "        (conv_height, conv_width, num_anchors, num_box_params),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    for box in true_boxes:\n",
    "        # scale box to convolutional feature spatial dimensions\n",
    "        box_class = box[4:5]\n",
    "        box = box[0:4] * np.array(\n",
    "            [conv_width, conv_height, conv_width, conv_height])\n",
    "        i = np.floor(box[1]).astype('int')\n",
    "        j = min(np.floor(box[0]).astype('int'),1)\n",
    "        best_iou = 0\n",
    "        best_anchor = 0\n",
    "                \n",
    "        for k, anchor in enumerate(anchors):\n",
    "            # Find IOU between box shifted to origin and anchor box.\n",
    "            box_maxes = box[2:4] / 2.\n",
    "            box_mins = -box_maxes\n",
    "            anchor_maxes = (anchor / 2.)\n",
    "            anchor_mins = -anchor_maxes\n",
    "\n",
    "            intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "            intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "            intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "            intersect_area = intersect_wh[0] * intersect_wh[1]\n",
    "            box_area = box[2] * box[3]\n",
    "            anchor_area = anchor[0] * anchor[1]\n",
    "            iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_anchor = k\n",
    "                \n",
    "        if best_iou > 0:\n",
    "            detectors_mask[i, j, best_anchor] = 1\n",
    "            adjusted_box = np.array(\n",
    "                [\n",
    "                    box[0] - j, box[1] - i,\n",
    "                    np.log(box[2] / anchors[best_anchor][0]),\n",
    "                    np.log(box[3] / anchors[best_anchor][1]), box_class\n",
    "                ],\n",
    "                dtype=np.float32)\n",
    "            matching_true_boxes[i, j, best_anchor] = adjusted_box\n",
    "    return detectors_mask, matching_true_boxes\n",
    "########################################Gathered code ends here.\n",
    "\n",
    "                         ######################your code starts here..\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# GRADED FUNCTION: yolo_filter_boxes\n",
    "\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "      \n",
    "    box_scores = box_confidence*box_class_probs\n",
    "    box_classes = K.argmax(box_scores,axis=-1)\n",
    "    box_class_scores = K.max(box_scores,axis=-1)\n",
    "    \n",
    "    filtering_mask = box_class_scores>=threshold\n",
    "\n",
    "    scores = tf.boolean_mask(box_class_scores,filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes,filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes,filtering_mask)\n",
    "    return scores, boxes, classes\n",
    "#########################testing\n",
    "with tf.compat.v1.Session() as test_a:\n",
    "    box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))\n",
    "\n",
    "######################JAI DONT'T IMPLEMENT IT BEFORE FIRST TESTING WITHOUT IT.YOU HAVE INCLUDED IT IN NON_MAX_SUPRESSION\n",
    "def iou(box1, box2):\n",
    "   \n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "    xi1 = max(box1[0],box2[0])\n",
    "    yi1 = max(box1[1],box2[1])\n",
    "    xi2 = min(box1[2],box2[2])\n",
    "    yi2 = min(box1[3],box2[3])\n",
    "    inter_width = (xi2-xi1)\n",
    "    inter_height = (yi2-yi1)\n",
    "    inter_area = inter_width*inter_height\n",
    "    box1_area = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
    "    box2_area = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
    "    union_area = box1_area+box2_area-inter_area\n",
    "\n",
    "    iou = inter_area/union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4) \n",
    "print(\"iou for intersecting boxes = \" + str(iou(box1, box2)))\n",
    "\n",
    "## Test case 2: boxes do not intersect\n",
    "box1 = (1,2,3,4)\n",
    "box2 = (5,6,7,8)\n",
    "box2 = (5,6,7,8)\n",
    "print(\"iou for non-intersecting boxes = \" + str(iou(box1,box2)))\n",
    "\n",
    "## Test case 3: boxes intersect at vertices only\n",
    "box1 = (1,1,2,2)\n",
    "box2 = (2,2,3,3)\n",
    "print(\"iou for boxes that only touch at vertices = \" + str(iou(box1,box2)))\n",
    "\n",
    "## Test case 4: boxes intersect at edge only\n",
    "box1 = (1,1,3,3)\n",
    "box2 = (2,3,3,4)\n",
    "print(\"iou for boxes that only touch at edges = \" + str(iou(box1,box2)))\n",
    "\n",
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    \n",
    "    \n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')    \n",
    "    tf.compat.v1.keras.backend.get_session().run(tf.compat.v1.variables_initializer([max_boxes_tensor])) \n",
    "\n",
    "    nms_indices = tf.image.non_max_suppression(\n",
    "                                              boxes,\n",
    "                                              scores,\n",
    "                                            max_boxes_tensor,\n",
    "                                            iou_threshold=0.5)\n",
    "\n",
    "    scores = K.gather(scores,nms_indices)\n",
    "    boxes = K.gather(boxes,nms_indices)\n",
    "    classes = K.gather(classes,nms_indices)\n",
    "    return scores, boxes, classes\n",
    "#####################################testing\n",
    "\n",
    "with tf.compat.v1.Session() as test_b:\n",
    "    scores = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random.normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))\n",
    "\n",
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "   \n",
    "    \n",
    "\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=score_threshold)\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes=max_boxes,iou_threshold=iou_threshold)\n",
    "\n",
    "    return scores, boxes, classes\n",
    "###############################testing with random values\n",
    "with tf.compat.v1.Session() as test_b:\n",
    "    yolo_outputs = (tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))\n",
    "####################################################################\n",
    "sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "class_names = read_classes(r\"D:\\two_class.txt\")\n",
    "anchors = read_anchors(r\"D:\\yolo_anchors.txt\")\n",
    "image_shape = (720., 1280.)    \n",
    "\n",
    "yolo_model.summary()\n",
    "\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "\n",
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
